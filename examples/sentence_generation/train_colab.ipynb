{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generation-train-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talkin24/nlp_with_BERT_GPT/blob/main/examples/sentence_generation/train_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p36hSZiX6RNF"
      },
      "source": [
        "# 패키지 설치하기\n",
        "\n",
        "TPU 관련 패키지를 설치합니다. TPU 사용시 아래 라인 첫 문자(#)를 지우고 수행하세요. GPU를 쓴다면 아래 라인을 실행할 필요가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRTSTtBFO8jo"
      },
      "source": [
        "# TPU 사용시 아래 라인 첫 문자(#)를 지우고 수행하세요.\n",
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YixrCxo8O8N_"
      },
      "source": [
        "TPU 이외에 의존성 있는 패키지를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U3MeuPe4HkP",
        "outputId": "fe754e26-7bec-44f7-a352-41147a8bf7c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ratsnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 778 kB/s \n",
            "\u001b[?25hCollecting flask-cors>=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting transformers==4.10.0\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n",
            "Collecting Korpora>=0.2.0\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\n",
            "Collecting flask-ngrok>=0.0.25\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting pytorch-lightning==1.3.4\n",
            "  Downloading pytorch_lightning-1.3.4-py3-none-any.whl (806 kB)\n",
            "\u001b[K     |████████████████████████████████| 806 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting fsspec[http]>=2021.4.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.5)\n",
            "Collecting torchmetrics>=0.2.0\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 36.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.63.0)\n",
            "Collecting PyYAML<=5.4.1,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.6.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0->ratsnlp) (3.10.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n",
            "Collecting xlrd>=1.2.0\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting dataclasses>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 53.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=cc72d3582d4b6b7a2ef1be75d1c0de04c14ff476c38b86d9f5c37f7f4ddf478d\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, pyDeprecate, fsspec, aiohttp, xlrd, torchmetrics, tokenizers, sacremoses, huggingface-hub, future, dataclasses, transformers, pytorch-lightning, Korpora, flask-ngrok, flask-cors, ratsnlp\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed Korpora-0.2.0 PyYAML-5.4.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 frozenlist-1.3.0 fsspec-2022.3.0 future-0.18.2 huggingface-hub-0.5.1 multidict-6.0.2 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 ratsnlp-1.0.1 sacremoses-0.0.49 tokenizers-0.10.3 torchmetrics-0.7.3 transformers-4.10.0 xlrd-2.0.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skjaa0Gk6d_X"
      },
      "source": [
        "# 구글 드라이브 연동하기\n",
        "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCGKzLXJuED"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML-ubp246uzI"
      },
      "source": [
        "# 각종 설정\n",
        "모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtoPBSH4v31j"
      },
      "source": [
        "import torch\n",
        "from ratsnlp.nlpbook.generation import GenerationTrainArguments\n",
        "args = GenerationTrainArguments(\n",
        "    pretrained_model_name=\"skt/kogpt2-base-v2\",\n",
        "    downstream_corpus_name=\"nsmc\",\n",
        "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-generation\",\n",
        "    max_seq_length=32,\n",
        "    batch_size=32 if torch.cuda.is_available() else 4,\n",
        "    learning_rate=5e-5,\n",
        "    epochs=3,\n",
        "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
        "    seed=7,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RjaTAr7D4M"
      },
      "source": [
        "# 랜덤 시드 고정\n",
        "학습 재현을 위해 랜덤 시드를 고정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuacSUSd7JRf"
      },
      "source": [
        "from ratsnlp import nlpbook\n",
        "nlpbook.set_seed(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeTvf0bc9bbV"
      },
      "source": [
        "# 로거 설정\n",
        "메세지 출력 등을 위한 logger를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "251gdehZ9iPZ"
      },
      "source": [
        "nlpbook.set_logger(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUazvWL7Pry"
      },
      "source": [
        "# 말뭉치 다운로드\n",
        "실습에 사용할 말뭉치(NSMC)를 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyaJgPA7Zxi"
      },
      "source": [
        "from Korpora import Korpora\n",
        "Korpora.fetch(\n",
        "    corpus_name=args.downstream_corpus_name,\n",
        "    root_dir=args.downstream_corpus_root_dir,\n",
        "    force_download=args.force_download,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DnwLCKB7cRq"
      },
      "source": [
        "# 토크나이저 준비\n",
        "토큰화를 수행하는 토크나이저를 선언합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlcoBivi7hIY"
      },
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    eos_token=\"</s>\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9s8znA17ovP"
      },
      "source": [
        "from ratsnlp.nlpbook.generation import NsmcCorpus, GenerationDataset\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
        "corpus = NsmcCorpus()\n",
        "train_dataset = GenerationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"train\",\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=RandomSampler(train_dataset, replacement=False),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOAACuBY7vem"
      },
      "source": [
        "# 테스트 데이터 구축\n",
        "학습 중에 평가할 테스트 데이터를 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcm1tgfq7y84"
      },
      "source": [
        "val_dataset = GenerationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"test\",\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HztMCywb70e9"
      },
      "source": [
        "# 모델 초기화\n",
        "프리트레인이 완료된 GPT2 모델을 읽고, 문장 생성 모델을 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "staYwMx88MWQ"
      },
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained(\n",
        "    args.pretrained_model_name\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYtJXijM8PN8"
      },
      "source": [
        "# 학습 준비\n",
        "Task와 Trainer를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FFn4MSz8SWu"
      },
      "source": [
        "from ratsnlp.nlpbook.generation import GenerationTask\n",
        "task = GenerationTask(model, args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18W4vRtR8UTx"
      },
      "source": [
        "trainer = nlpbook.get_trainer(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n",
        "준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-generation`)에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDr3M_nF8l7M"
      },
      "source": [
        "trainer.fit(\n",
        "    task,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}